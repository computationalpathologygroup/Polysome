{
  "name": "integration_test_vllm",
  "description": "Integration test for vLLM inference engine with quantized gemma-3-4b-it",
  "data_dir": "tests/integration/data",
  "output_dir": "output/integration_tests",
  "prompts_dir": "src/polysome/templates/prompts",
  "log_dir": "output/integration_tests/logs",
  "workflow_settings": {
    "optimize_for_engines": false,
    "comment": "Integration test - vLLM engine"
  },
  "nodes": [
    {
      "id": "load_test_data",
      "type": "load",
      "params": {
        "name": "load_questions",
        "input_data_path": "test_questions.json",
        "primary_key": "id",
        "output_file_name": "loaded_questions.jsonl",
        "resume": true
      },
      "dependencies": []
    },
    {
      "id": "generate_answers_vllm",
      "type": "text_prompt",
      "params": {
        "name": "simple_qa",
        "template_context_map": {},
        "system_prompt_file": "system_prompt.txt",
        "user_prompt_file": "user_prompt.txt",
        "few_shot_lines_file": "few_shot.jsonl",
        "num_few_shots": 2,
        "model_name": "RedHatAI/gemma-3-4b-it-quantized.w4a16",
        "inference_engine": "vllm",
        "engine_options": {
          "tensor_parallel_size": 1,
          "gpu_memory_utilization": 0.8,
          "max_model_len": 4096,
          "dtype": "auto",
          "trust_remote_code": true
        },
        "generation_options": {
          "max_tokens": 256,
          "temperature": 0.7,
          "top_p": 0.9
        },
        "batch_size": 5,
        "output_data_attribute": "answer",
        "resume": true
      },
      "dependencies": ["load_test_data"]
    }
  ]
}
